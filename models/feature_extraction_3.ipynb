{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make my plots pretty!\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Part 3\n",
    "\n",
    "Yesterday's experiments seems to yield good features. I have one more trick up my sleeve as far as feature generation is concerned: combining tf-idf and word embeddings.\n",
    "\n",
    "Then we'll try some other classification methods like random forests and XGBoost.\n",
    "\n",
    "I'll also refactor some of my code into python functions that can be reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Just load the small training/validation sets we made, no need the whole model.\n",
    "import pickle\n",
    "train_set = pickle.load(open('../data/train_small.pickle', 'r'))\n",
    "valid_set = pickle.load(open('../data/valid_small.pickle', 'r'))\n",
    "print(len(train_set))\n",
    "print(len(valid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['is', 'michael', 'phelps', 'the', 'greatest', 'swimmer', 'ever', '?'],\n",
       " ['is',\n",
       "  'michael',\n",
       "  'phelps',\n",
       "  'the',\n",
       "  'greatest',\n",
       "  'swimmer',\n",
       "  'of',\n",
       "  'all',\n",
       "  'time',\n",
       "  '?'],\n",
       " 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What each data point looks like. Pretty basic.\n",
    "train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400000, 100])\n"
     ]
    }
   ],
   "source": [
    "# Load word embeddings. 100d to be quick\n",
    "import sys\n",
    "sys.path.append('../models/')\n",
    "import data\n",
    "reload(data)\n",
    "\n",
    "dictionary, embed = data.load_embeddings('../data/glove.6B.100d.txt')\n",
    "print(embed.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence to word embedding.\n",
    "reload(data)\n",
    "embed_out = torch.zeros((8,100))\n",
    "data.embed_words(dictionary, embed, ['the', 'quick', 'brown', 'fox'], embed_out[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.0382 -0.2449  0.7281 -0.3996  0.0832  0.0440 -0.3914  0.3344 -0.5755  0.0875\n",
       "-0.4315 -0.2204 -0.2268 -0.1022 -0.3186 -0.1181 -0.0934 -0.0698 -0.2903 -0.3401\n",
       "-0.4381 -0.0994 -0.2604 -1.1084  0.1055 -0.0545  0.4487  0.0617 -0.5880 -0.2174\n",
       " 0.1692 -0.9978  0.2443 -0.7969  0.0364 -0.5613  0.1731  0.2929 -0.4329 -0.8227\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 6x10]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "embed_out[:6,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.4866 -1.3207 -0.8360 -0.6047 -0.1985 -0.8930  1.3665  0.6613  0.8760 -0.7007\n",
       "-0.1408 -0.0129 -0.6157  1.5378 -0.6237  0.7065  0.8764 -0.4265  0.2084  0.7650\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-1.3122  0.7493 -0.6223 -1.3783  0.3999 -0.0679 -1.3426 -1.5309 -0.4686  2.0079\n",
       "[torch.FloatTensor of size 4x10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we load an unknown word, embedding should be zeroed out\n",
    "reload(data)\n",
    "embed_out = torch.randn((8,100))\n",
    "print(data.embed_words(dictionary, embed, ['kkkkzkzkkzkz'], embed_out[2:3]))\n",
    "embed_out[:4,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "Let's count TF-IDF on the whole training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from 'data.pyc'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_word_tokenized = data.load_tokenized('../data/train_q1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 404288\n",
      "('what', 'is', 'one', 'key', 'criteria', 'or', 'computer', 'part', 'that', 'makes', 'a', 'computer', 'fast', 'for', 'gaming', '?')\n"
     ]
    }
   ],
   "source": [
    "q2_word_tokenized = data.load_tokenized('../data/train_q2.txt')\n",
    "print('len:', len(q2_word_tokenized))\n",
    "print(q2_word_tokenized[1234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "tf = TfidfVectorizer()\n",
    "#itertools.chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 2.81 s, total: 16.4 s\n",
      "Wall time: 16.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tf.fit(itertools.imap(lambda x: ' '.join(x), itertools.chain(q1_word_tokenized, q2_word_tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save this so I don't have to do this again.\n",
    "pickle.dump(tf, open('tfidf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = pickle.load(open('../data/tfidf.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does one of these tf-idf vectors look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'are', 'some', 'of', 'the', 'most', 'epic', 'dialogues', 'in', 'hollywood', 'movies', '?']\n",
      "  (0, 58228)\t0.102677315476\n",
      "  (0, 53417)\t0.104353842032\n",
      "  (0, 49758)\t0.210069623875\n",
      "  (0, 37679)\t0.144075882446\n",
      "  (0, 35383)\t0.322653773137\n",
      "  (0, 35253)\t0.251826328892\n",
      "  (0, 26566)\t0.132532742595\n",
      "  (0, 25140)\t0.402384762401\n",
      "  (0, 18537)\t0.506381771442\n",
      "  (0, 15611)\t0.537732845086\n",
      "  (0, 4424)\t0.145261985783\n"
     ]
    }
   ],
   "source": [
    "sentence = train_set[2525][0]\n",
    "print(sentence)\n",
    "sentence_sparse = tf.transform([' '.join(sentence)])\n",
    "print(sentence_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can precompute tfidf-reweighted sentence embeddings\n",
    "reload(data)\n",
    "tfidf_embed_out = torch.zeros((16, 100))\n",
    "data.get_reweighted_embeddings(tf, dictionary, embed, sentence, tfidf_embed_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.0156  0.0394  0.0917  ...  -0.0278  0.0228  0.0946\n",
       " 0.1278  0.0215 -0.3566  ...  -0.3855 -0.0945  0.5576\n",
       " 0.0656 -0.0124  0.1186  ...  -0.0196  0.2303  0.0804\n",
       "          ...             ⋱             ...          \n",
       "-0.0040 -0.0256  0.0760  ...  -0.0152  0.0864  0.0282\n",
       " 0.0895  0.2036  0.2927  ...  -0.0610  0.0177 -0.0318\n",
       " 0.3734 -0.1171  0.3375  ...   0.0275  0.3118  0.2352\n",
       "[torch.FloatTensor of size 11x100]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_embed_out[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.1518  0.3841  0.8934  ...  -0.2712  0.2216  0.9211\n",
       "-0.5153  0.8319  0.2246  ...  -1.2024  1.1304  0.3479\n",
       "-0.1445  0.5602  0.2054  ...  -0.3640  0.9161  0.8209\n",
       "          ...             ⋱             ...          \n",
       " 0.0857 -0.2220  0.1657  ...  -0.0743  0.7581 -0.3424\n",
       " 0.9280 -0.2910  0.8388  ...   0.0685  0.7749  0.5844\n",
       " 0.2032 -0.0385  0.3675  ...  -0.0609  0.7138  0.2492\n",
       "[torch.FloatTensor of size 11x100]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with:\n",
    "embed_out = torch.zeros((len(sentence), 100))\n",
    "print(data.embed_words(dictionary, embed, sentence, embed_out))\n",
    "embed_out[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_word_len = 30\n",
    "embed_size = 100\n",
    "q1_train_all = torch.zeros((len(train_set), max_word_len, embed_size))\n",
    "q2_train_all = torch.zeros((len(train_set), max_word_len, embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(data)\n",
    "vectorized_train = data.vectorize(dictionary, embed, train_set, q1_train_all, q2_train_all, tf=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_valid_all = torch.zeros((len(valid_set), max_word_len, embed_size))\n",
    "q2_valid_all = torch.zeros((len(valid_set), max_word_len, embed_size))\n",
    "vectorized_valid = data.vectorize(dictionary, embed, valid_set, q1_valid_all, q2_valid_all, tf=tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vectors\n",
    "\n",
    "Now each sentence is encoded as an Lx30 matrix. Let's use the vectorization techniques. The results of each should be a NxD matrix, one row for each training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import features\n",
    "reload(features)\n",
    "\n",
    "# The simplest thing would be averaging all the per-word vectors to get a single sentence embedding.\n",
    "# This is a mean of the tfidf-weighted GloVE vectors.\n",
    "q1_train_mean = q1_train_all.mean(dim=1).squeeze()\n",
    "q2_train_mean = q2_train_all.mean(dim=1).squeeze()\n",
    "q1_valid_mean = q1_valid_all.mean(dim=1).squeeze()\n",
    "q2_valid_mean = q2_valid_all.mean(dim=1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4750\n",
       " 0.5100\n",
       " 0.5350\n",
       " 0.6400\n",
       " 0.6250\n",
       " 0.5850\n",
       " 0.7550\n",
       " 0.6900\n",
       " 0.5250\n",
       " 0.4350\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permutation test\n",
    "reload(features)\n",
    "features.permute(vectorized_train[:100], distance='absolute', n_trials=200)[0, 10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1103\n",
      " 0.0540\n",
      " 0.1230\n",
      " 0.0292\n",
      " 0.0065\n",
      " 0.0028\n",
      " 0.0036\n",
      " 0.0204\n",
      " 0.0218\n",
      " 0.0187\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4562\n",
       " 0.5696\n",
       " 0.5389\n",
       " 0.6754\n",
       " 0.6581\n",
       " 0.5696\n",
       " 0.7164\n",
       " 0.6837\n",
       " 0.5438\n",
       " 0.4431\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify implementation\n",
    "\n",
    "q1 = vectorized_train[0][0]\n",
    "q2 = vectorized_train[0][1]\n",
    "q1_vs = list(q1.chunk(3)) + list(q2.chunk(4))\n",
    "len(q1_vs)\n",
    "q1_mean = q1.mean(dim=0)\n",
    "q2_mean = q2.mean(dim=0)\n",
    "base_diff = (q1_mean - q2_mean).abs()\n",
    "print(base_diff[0, 30:40])\n",
    "len_q1 = q1.size(0)\n",
    "len_q2 = q2.size(0)\n",
    "sum_len = len_q1 + len_q2\n",
    "\n",
    "running_diff = torch.zeros(100)\n",
    "\n",
    "for t in xrange(20000):\n",
    "    np.random.shuffle(q1_vs)\n",
    "    qs1 = torch.stack(q1_vs[:len_q1])\n",
    "    qs2 = torch.stack(q1_vs[len_q1:])\n",
    "    qs1_mean = qs1.mean(dim=0)\n",
    "    qs2_mean = qs2.mean(dim=0)\n",
    "    diff = (qs1_mean - qs2_mean).abs()\n",
    "    running_diff.add_((diff > base_diff).squeeze().float())\n",
    "    \n",
    "val = (running_diff / 20000)\n",
    "val[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5199  0.3491  0.6506  0.4932  0.5075  0.5595  0.5885\n",
       "[torch.FloatTensor of size 1x7]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[3][torch.randperm(34)[:21]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.7309  0.9930  0.8515  0.2611  0.9239  0.0191  0.3806\n",
       " 0.0496  0.1212  0.4117  0.8901  0.2001  0.9738  0.0644\n",
       " 0.4557  0.8290  0.9228  0.0063  0.4309  0.8844  0.4808\n",
       " 0.6261  0.0879  0.8273  0.5520  0.2190  0.4143  0.7219\n",
       " 0.1603  0.0601  0.4650  0.5642  0.0548  0.3870  0.2903\n",
       " 0.5868  0.6631  0.4622  0.1865  0.2093  0.6016  0.5310\n",
       " 0.4925  0.1365  0.7357  0.8064  0.9292  0.8576  0.9671\n",
       " 0.7286  0.4199  0.7516  0.9416  0.6415  0.5607  0.5838\n",
       " 0.7414  0.0938  0.1671  0.2931  0.6318  0.5355  0.8770\n",
       " 0.6271  0.0864  0.9116  0.4303  0.8347  0.3608  0.9880\n",
       "[torch.FloatTensor of size 10x7]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.rand((10, 7))\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "[torch.FloatTensor of size 10x7]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = torch.zeros((10,7))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5000  0.3000  0.6000  0.3000  0.5000  0.4000  0.4000\n",
       "[torch.FloatTensor of size 1x7]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ((j - .6) * 10).ceil().clamp(0, 1).mean(dim=0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.6000  0.4000  0.6000  0.6000  0.5000  0.7000  0.7000\n",
       "[torch.FloatTensor of size 1x7]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(j - b.repeat(10,1)).ceil().clamp(0, 1).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
